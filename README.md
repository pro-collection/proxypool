# golang 实现自己的 IP 代理池

## 爬虫与 IP 代理池不得不说的故事

说到爬虫， 那么 IP 代理池是一个绕不开的话题。 现在很多网站为了防止别人爬取自己的站点， 采用的手段很粗暴， 但凡识别到有爬虫迹象的 IP 直接封禁该 IP 的访问即可。
那问题就来了， 服务器的 IP 地址是静态的， 就算是家用电脑，IP 地址大多数情况下也是固定静态的。 一旦被某网站封禁，就意味着你的爬虫废了。 

这个是爬虫的防御手段问题， 那么涉及到爬虫的成本问题， 很多人会直接通过 HTTP 请求去获取人家渲染好的 HTML 模板爬取内容， 甚至直接注入 cookie 之后， 用服务器发送请求， 去获取别人站点的数据。
很负责人的告诉大家， 这样被封禁 IP 的非常高， 我在 18 年学习 python 爬虫框架 Scrapy 的时候经常遇到 IP 被封禁访问的情况。 （[附加链接 18 年学习的链接](https://github.com/yanlele/python-index/tree/master/book/02%E3%80%81Scrapy%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0)）

为了让自己的爬虫没有那么容易被封禁， 爬虫选手们就需要尽力让自己的爬虫伪装成一个真正的用户行为。这个时候就要祭出各种的无头浏览器技术，例如：`Puppeteer、PhantomJS` 等；

尽管你有无头浏览器技术， 尽管你伪装成了用户行为， 但是在站点行为分析和访问量分析的话， 还是有一定概率被定盯上。

那么如何从底层技术上突破爬虫封锁呢？**就是 IP 代理池**。

IP 代理池是啥？就是你的爬虫访问 A 网站的时候， 不是你自己的 IP ， 是一个别人的 IP 在帮你爬取数据，使用别人的 IP 代理你去爬取数据， 然后爬取到了数据之后再给你。 
如果 IP 被封锁， 那么也是别人的 IP 被封锁， 跟你没有任何关系。 这样可以代理的 IP 成千上万的话， 就形成了 IP 代理池。

所以对于通常有 IP 代理池的爬虫，在爬取数据的时候， 不再需要担心自己本身的 IP 被封禁了。 

## 为何要用 golang 来实现？

golang 的优势我就不多说了。 
直接说结果吧，这个代理池程序， 最后可以打包为一个 20MB 的可执行文件， 丢谁都可以直接运行， 没有任何依赖， 内存消耗很低， 1核1G的机器都可以跑的飞快。

## 程序的开始前言

先说说我们实现 IP 代理池的原理。 

实际上网上有很多付费的 IP 代理池， 稳定且高效， 高匿不说， IP 量还异常的大。 但是架不住费用非常高呀，到底费用有多高， 各位小伙伴们， 网上搜索一下就知道了。 
所以这种高费用的商业 IP 代理池， 并不适合于大家用于学习。所以我们要实现一下自己的 IP 代理池， 简单学习爬虫就够用了。 

那么我们是如何实现的呢？
其实这个也非常简单， 有一些网上有一些IP代理网站， 为了吸引别人来使用， 会放出一些免费的 IP 代理地址， 但是这些免费的 IP 代理地址变化非常快， 一般一两个小时就刷新一次， 而且速度较慢， 稳定性很低， 甚至有很多压根就没法用。 
我们就怕这些 IP 获取下来， 进行测速、筛选、分类， 做成我们的临时 IP 代理池， 对于学习爬虫的同学们来说， 其实也足够用了。

接下来我会一步一步拆解实现一个 IP 代理池；
当然具体的实现不是我原创的， github 有一位大神， 已经实现了一套 ip 代理池， 地址可以参考： https://github.com/henson/proxypool

但是大神使用的 IP 代理池是需要写入数据库的， 配置还挺复杂的。 本身这种实现方式的 IP 代理池， IP 变化都非常快， 其实没有必要存数据库；所以我们要对他的实现进行简化魔改。 

## 兵马未动日志先行

任何程序第一步要搭建自己的良好的日志环境。 没有日志， 就没有任何线上排查运维可言， 就是蒙着眼睛的裸奔瞎子



